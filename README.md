
# ğŸ“š IMDB Movie Reviews Text Classification

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![Scikit-learn](https://img.shields.io/badge/scikit--learn-1.5.2-green.svg)

## ğŸ“ Table of Contents
- [ğŸ“š Overview](#-overview)
- [ğŸ” Project Details](#-project-details)
  - [Objective](#objective)
  - [Dataset](#dataset)
  - [Methodology](#methodology)
- [âœ¨ Key Features](#-key-features)
- [âš™ï¸ Requirements](#ï¸-requirements)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ“ˆ Results and Insights](#-results-and-insights)
- [ğŸ“„ License](#-license)
- [ğŸ“§ Contact](#-contact)

## ğŸ“š Overview

Welcome to the **IMDB Movie Reviews Text Classification** project! This repository offers an efficient and streamlined approach for classifying the sentiment of IMDB movie reviews, focusing on resource-friendly methods. Ideal for students, data enthusiasts, and professionals, this project highlights best practices for text classification in NLP.

## ğŸ” Project Details

### Objective
To classify IMDB movie reviews as **positive** or **negative** using models designed for effective and efficient text classification in computationally constrained environments.

### Dataset
- **Source**: IMDB Movie Reviews
- **Description**: A labeled dataset with text-based movie reviews for binary sentiment classification.
- **Access**: [IMDB Dataset on Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)

### Methodology
1. **Data Preprocessing**
   - **Cleaning**: Removing unnecessary characters, HTML tags, and stop words.
   - **Tokenization**: Breaking text into meaningful tokens for analysis.
   - **Feature Extraction**: Applying techniques like TF-IDF to convert text into numerical features.

2. **Model Selection**
   - **Logistic Regression**: Effective for binary classification.
   - **Naive Bayes**: Lightweight and suitable for text data, providing a balance between efficiency and accuracy.

3. **Evaluation Metrics**
   - **Accuracy**: Measures prediction correctness.
   - **Precision & Recall**: Assess the quality of positive predictions and ability to find relevant instances.
   - **F1-Score**: A single performance metric that combines precision and recall.

## âœ¨ Key Features
- **Resource Efficiency**: Models and techniques are optimized for limited computational power.
- **Scalability**: Methods can be easily scaled for larger datasets or more complex environments.
- **Educational Value**: Detailed explanations and clear steps make this project ideal for learning NLP and text classification fundamentals.
- **Reproducibility**: Easy-to-follow instructions and thorough documentation.

## âš™ï¸ Requirements
- **Python**: Version 3.8 or higher
- **Libraries**:
  - `scikit-learn`
  - `pandas`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `nltk`

_All dependencies are listed in `requirements.txt`._



## ğŸ“ˆ Results and Insights

The project provides an in-depth evaluation of each model, with metrics like accuracy, precision, recall, and F1-score. Insights into the performance of different approaches within limited-resource constraints help users understand the efficiency vs. accuracy trade-offs.

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

## ğŸ“§ Contact

If you have questions or feedback, feel free to reach out:

- **Email**: [fatimaliyva@gmail.com](mailto:fatimaliyva@gmail.com)
- **LinkedIn**: [Fatima Aliyeva](https://www.linkedin.com/in/fatima-aliyeva-/)
- **GitHub**: [FatimaAliyeva01](https://github.com/FatimaAliyeva01)

---
